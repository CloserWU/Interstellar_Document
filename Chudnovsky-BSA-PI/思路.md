解决思路：

考虑到圆周率小数点后三千两百万位，一定需要特殊的数据结构，并且考虑计算时间的话，也需要效率很高的算法。

所以问题归结于怎样提高精度和速度和选择合适算法的问题。

首先，在算法方面我找了马青公式，马青公式使用级数展开的方法计算百万以下级别精度的圆周率，速度还算满意，但是精度百万以后，速度很慢，并且一般的数据结构也无法满足需求。

同时在数据结构方面我想到用显卡加速。我尝试着引入tensorflow-gpu框架，改造马青公式，并且将数据类型换位tensorflow中的数据类型，但是实践发现，这个方案不行。

第一个原因是，float64远达不到题目所需精度。

第二个原因是，GPU不合适本题。GPU加速在数组并行计算方面有很大优势，比如矩阵A、B相加，代码上只用A+B即可，但是实际工作是每个矩阵中每个元素相加，所以背后的工作量很多，需要并行计算来提速，又因为GPU很擅长并行处理浮点数据。所以GPU加速使用多维矩阵的运算。但是本题数据结构并不是矩阵，而是远大于float64和int64的高精度浮点和整数。所以使用GPU不合适。

所以使用GPU加速和马青公式都被否定。

然后我查找资料知道，python本身支持大数运算，所以退而求其次，用python本身的大数运算，虽然时间较慢。

在算法方面我又尝试蒙特卡洛方法。但是实践发现，蒙特卡洛方法精度极低，无法满足本题需求。

 

经过长时间的查找资料，我得知SUPERPI专业计算PI的软件使用的是高斯-勒让德算法。但是查找本方法后，无果而终。

然后又查找资料得知，有一种算法基于快速收敛的超几何级数，是楚德诺夫斯基(chudnovsky)算法。本方法收敛迅速，且精度相当高。经过查找资料尝试后，发现虽然精度保证，计算速度很慢。

这是算法复杂度太高的原因，且数据结构也又问题。因为python本身大数运算速度很慢。

现在的情况是优秀的算法已经找到，但是有待优化，且数据类型亟待改进。

又经过漫长的查找资料，发现GNU有一个包是专门进行高精度科学运算的，名字为gmp，支持C/C++，并且恰好这个包也有适用于python的版本，叫gmpy2。同时查到一个非常优秀的算法，将楚德诺夫斯基(chudnovsky)算法进行改进，采用二进制分裂算法，加入递归的算法计算pi。其算法复杂度只有O(n)。

所以到目前为止，算法和数据类型的问题都解决了。然后就是程序实现的过程。

……